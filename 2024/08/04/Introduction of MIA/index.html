



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="张前的小屋" href="https://ckti.github.io/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="张前的小屋" href="https://ckti.github.io/atom.xml" />
<link rel="alternate" type="application/json" title="张前的小屋" href="https://ckti.github.io/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  

<link rel="canonical" href="https://ckti.github.io/2024/08/04/Introduction%20of%20MIA/">



  <title>
Introduction of Membership Interface Attack - 成员推断攻击 - 阅读笔记 |
CKT1i's blog = 张前的小屋</title>
<meta name="generator" content="Hexo 7.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">Introduction of Membership Interface Attack
  </h1>
  
<div class="meta">
  <span class="item" title="Created: 2024-08-04 21:28:25">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">Posted on</span>
    <time itemprop="dateCreated datePublished" datetime="2024-08-04T21:28:25+08:00">2024-08-04</time>
  </span>
  <span class="item" title="Symbols count in article">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">Symbols count in article</span>
    <span>16k</span>
    <span class="text">words</span>
  </span>
  <span class="item" title="Reading time">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">Reading time</span>
    <span>14 mins.</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="Toggle navigation bar">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">CKT1i's blog</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://images.weserv.nl/?url=https://raw.github.com/ckt1i/blogimage/main/pic17.jpg"></li>
          <li class="item" data-background-image="https://images.weserv.nl/?url=https://raw.github.com/ckt1i/blogimage/main/pic21.jpg"></li>
          <li class="item" data-background-image="https://images.weserv.nl/?url=https://raw.github.com/ckt1i/blogimage/main/pic1.jpg"></li>
          <li class="item" data-background-image="https://images.weserv.nl/?url=https://raw.github.com/ckt1i/blogimage/main/pic16.jpg"></li>
          <li class="item" data-background-image="https://images.weserv.nl/?url=https://raw.github.com/ckt1i/blogimage/main/pic13.jpg"></li>
          <li class="item" data-background-image="https://images.weserv.nl/?url=https://raw.github.com/ckt1i/blogimage/main/pic22.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">Home</a></span><i class="ic i-angle-right"></i>
<span  itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ReadingNotes/" itemprop="item" rel="index" title="In 阅读笔记"><span itemprop="name">阅读笔记</span></a>
<meta itemprop="position" content="1" /></span>
<i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ReadingNotes/MIA/" itemprop="item" rel="index" title="In 成员推断攻击"><span itemprop="name">成员推断攻击</span></a>
<meta itemprop="position" content="2" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="en">
  <link itemprop="mainEntityOfPage" href="https://ckti.github.io/2024/08/04/Introduction%20of%20MIA/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.png">
    <meta itemprop="name" content="C.K. Tii">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="张前的小屋">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <p>This is the English version of <a href="/public/2024/08/02/Introduction%20of%20MIA_CN/index.html">this</a> blog. The translation may be not correct, if there are any mistakes, please contact me for delivering suggestions.</p>
<h1 id="prelimaries-defination-and-classification"><a class="markdownIt-Anchor" href="#prelimaries-defination-and-classification">#</a> Prelimaries ,Defination and classification</h1>
<h2 id="prelimaries-machine-learning"><a class="markdownIt-Anchor" href="#prelimaries-machine-learning">#</a> Prelimaries-- Machine learning</h2>
<p>Machine learning (ML) is the study of computer algorithms that improve automatically through experience and by learning from data. Generally, it can be  be divided into these two categories</p>
<p><strong>Supervised Learning</strong> :Uses labeled data where input-output pairs are known to train models. It aims to predict or classify new data based on learned patterns, minimizing the error between predicted and actual outcomes.</p>
<p><strong>Unsupervised Learning</strong> :Works with unlabeled data to identify hidden patterns or structures. It clusters or finds relationships within the data without predefined labels.</p>
<h2 id="membership-interface-attackdefination"><a class="markdownIt-Anchor" href="#membership-interface-attackdefination">#</a> Membership Interface Attack–Defination</h2>
<p>Membership interface attack (MIA) is a method of obtaining the data being trained in the targeted ML models byThe main thought of MIA is forming a models that can repersents the membership of the target models. training similar model called shadow model and training a classifier to check whether a data is being trained in the targeted ML model.</p>
<h3 id="shadow-models"><a class="markdownIt-Anchor" href="#shadow-models">#</a> Shadow models</h3>
<p>The main thought of MIA is forming a models that can repersents the membership of the target models.</p>
<p><img data-src="https://raw.githubusercontent.com/ckt1i/blogimage/main/Shadow%20model.png" alt="shadow models and training"></p>
<h2 id="basic-taxonomy-of-mia"><a class="markdownIt-Anchor" href="#basic-taxonomy-of-mia">#</a> Basic Taxonomy of MIA</h2>
<h3 id="based-on-informations"><a class="markdownIt-Anchor" href="#based-on-informations">#</a> based on informations</h3>
<p>Based on the informations of the target model attackers can get, the MIA can be divided into these two categories:</p>
<p><strong>White-box attack</strong>: Attackers can obtain all the information about the ML model, including the data distributions, training methods and relevant  parameters</p>
<p><strong>Black-box attack</strong>: Attackers can only get restricted informations, including restricted data distributions, training methods and parameters.</p>
<p>Compared with white-box attack, black-box attacks gets fewer informations, which leads it harder to achieve. However, the influence of a successful attacks can be  larger than it. Today , the mainstream of the research is also focusing on the black-box attacks.</p>
<h3 id="based-on-prediction-vectors"><a class="markdownIt-Anchor" href="#based-on-prediction-vectors">#</a> based on Prediction vectors</h3>
<p>The prediction vectors is a parameter for judging whether a data is in the models. Today, the main research of MIA can also be categorized based on prediction vectors in the following graph:</p>
<p><img data-src="https://raw.githubusercontent.com/ckt1i/blogimage/main/Prediction%20vectors.png" alt="Taxonomy of Prediction vectors"></p>
<h3 id="based-on-the-judgement-methods"><a class="markdownIt-Anchor" href="#based-on-the-judgement-methods">#</a> Based on the judgement methods</h3>
<h4 id="binary-classifier-based-mia"><a class="markdownIt-Anchor" href="#binary-classifier-based-mia">#</a> Binary Classifier Based MIA.</h4>
<p>The data can be classified as members or non-members by training a binary classifier for classify the models. the main method is as followed:</p>
<p><strong>Training the shadow models</strong>: Attackers use multiple shadow models that have the same or similar distributions of the target training sets to learn and training the shadow models.</p>
<p><strong>Collecting prediction models</strong>: Attackers will make search for the shadow training sets and get the prediction vectors of each data records. Each data of the vectors in shadow training data sets can be labeled as “Member” and the data in test data sets are labled “Non-member”</p>
<p><strong>Training the attack models</strong>: Form the “member”and “non-member”data sets based on the labeled datas , and training a binary classifier to form it.</p>
<p>By this, Identifying the complex problem of recognizing the member and non-member of the model is converted into the binary classifier problem.</p>
<h4 id="metric-based-membership-inference-attacks"><a class="markdownIt-Anchor" href="#metric-based-membership-inference-attacks">#</a> Metric Based Membership Inference Attacks</h4>
<p>Metric Based MIA obtain the relative metrics by collecting and analysing the prediction vectors and make analyzations by comparing the metrics and thresold values.</p>
<p>Compare with training the binary classifier, it is more simple and consume less computational resources. The next page will show the recent research realms of the analyse and settings.</p>
<p>Currently, the research on metric based MIA have these categories:</p>
<p><strong>Prediction Correctness Based MIA</strong>: If the target models predict the input data x correctly, then attackers recognized it as a member. The inituation of it is that if a data is in the real data, then the target model will predict the input data x correctly.</p>
<p><strong>Loss rate Based MIA</strong>: If the difference of the loss rate correspond to the target models and the lossrate of the origin data is less than a thresold, then attackers recognize it as a member. The inituation of it is that if the input data is in the true datas, then the loss rate of the target models is near to the total loss rate.</p>
<p><strong>Prediction Confidence Based MIA</strong>: If the prediction confidence of some records is larger than some thresold, then recognize it as a member. The inituation of it is that the target models will minimize the difference between it and the real models, so the prediction confidence will close to 1.</p>
<p><strong>Prediction Entropy Based MIA</strong>: If the prediction entropy of input a records is lower than a thresold, then recognize it as a member. The inituation is that the target model’s prediction entropy of the training data is larger than the prediction of entropy of the test data.</p>
<p><strong>Modified prediction Entropy Based MIA</strong>: Some opinion suggest that current prediction loss didn’t think of the ground truth label, so it may make some misjudgement of some datas, so in some papers, the algorithm of the prediction entropy is modified.</p>
<h1 id="relavant-research"><a class="markdownIt-Anchor" href="#relavant-research">#</a> Relavant research</h1>
<h2 id="research-on-the-classification-models"><a class="markdownIt-Anchor" href="#research-on-the-classification-models">#</a> Research on the classification models</h2>
<p>Since Shokri et al. introduced this attack method, there has been a growing body of research focused on this direction. Salem et al. discussed the assumptions of Membership Inference Attacks (MIA) and attempted to relax the implementation conditions, demonstrating that two of the shadow model assumptions are not necessary and proposing an indicator-based MIA approach. Yeom et al. also proposed two indicator-based MIA methods; Long et al. achieved MIA attacks on certain data by focusing on data with unique effects on the target model, enabling accurate inference in generalized models with similar training and testing accuracy.</p>
<p>Additionally, existing research has also targeted more restricted MIAs. Li and Zhang proposed transfer-based and perturbation-based MIAs. Transfer-based MIAs construct shadow models to simulate the target model, using the shadow model’s confidence to determine membership; perturbation-based MIAs introduce noise to create adversarial examples and distinguish members based on the severity of the perturbation. Choquette et al. introduced data augmentation-based MIAs and decision boundary distance-based MIAs. Data augmentation attacks target common data augmentation phenomena in machine learning systems, creating additional records through different augmentation strategies to query the target model for predictions. Decision boundary attacks estimate the distance of records to the model boundary, similar to Li and Zhang’s attacks. Successful MIA cases suggest that machine learning models may be more vulnerable to MIA than previously anticipated.</p>
<p>Aside from black-box MIA attacks, Nasir et al. introduced white-box MIA, which can be seen as an extension of black-box MIA, enhancing attack efficiency by leveraging additional information. They use the gradient of the target model’s prediction loss for inference and train a model to distinguish between members and non-members using the SGD algorithm. However, Leino and Fredrikson pointed out that the assumptions of this method are too stringent, requiring attackers to know the approximate distribution of the target dataset. They proposed a Bayes-optimal attack-based MIA method, enabling MIA without background knowledge of the target model.</p>
<h2 id="research-on-generative-models"><a class="markdownIt-Anchor" href="#research-on-generative-models">#</a> Research on Generative Models</h2>
<p>Corrent research on generative models are focusing on the generative adversarial network, whose models can be shown as follows:</p>
<p><img data-src="https://raw.githubusercontent.com/ckt1i/blogimage/main/GAN_architecture.png" alt=""></p>
<p>Hayes et al. were the first to propose Membership Inference Attacks (MIA) against generative models. For white-box attacks, attackers collect all records and compute confidence scores to make inferences; for black-box attacks, attackers collect records from the generator to train a local GAN that mimics the target GAN, and then use the local GAN discriminator for inference. Hilprecht et al. introduced two additional attacks: a Monte Carlo-based black-box attack and a VAE-based white-box attack. Hilprecht et al. proposed a set-based attack to determine whether a data point belongs to a set, while Liu et al. introduced a similar co-membership inference attack, determining dataset membership by analyzing the distance of a data point to the target data. Chen et al. proposed a general method where attackers continuously reconstruct the attack model through optimization, calculate the distance between the generated results of the attack model and the target model, and estimate the probability of data membership based on this distance.</p>
<h2 id="research-on-embedding-models"><a class="markdownIt-Anchor" href="#research-on-embedding-models">#</a> Research on Embedding Models：</h2>
<p>Current research primarily focuses on text and image embedding models. For text embedding models, attacks aim to infer membership of words or sentence pairs within a sliding window, using similarity scores to determine if they belong to a predefined set. For graph embedding models, attack methods involve using shadow models and confidence scores to infer whether nodes in the graph belong to specific categories, addressing node classification issues.</p>
<h2 id="research-on-regression-models"><a class="markdownIt-Anchor" href="#research-on-regression-models">#</a> Research on Regression Models：</h2>
<p>Gupta et al. were the first to conduct MIA (Membership Inference Attack) research on regression models for age prediction, achieving attacks through the construction of a white-box binary classification model.</p>
<h2 id="research-in-federated-learning"><a class="markdownIt-Anchor" href="#research-in-federated-learning">#</a> Research in Federated Learning：</h2>
<p>In federated learning, attackers can be either the central server or some of the participating clients. They can implement MIA by determining whether certain data was used in training the global model. Melis was the first to propose a gradient-based MIA by analyzing the update mechanism of the RNN training embeddings. Turex introduced heterogeneous FL (Federated Learning), which involves analyzing differences in aggregated parameters from different clients. Nasr et al. discussed how gradient ascent attacks can actively interfere with FL training. Hu et al. proposed source inference attacks aimed at determining which participants hold training records in FL. They argue that existing MIA attacks in FL overlook the source information of training members, which could lead to further privacy issues.</p>
<h1 id="factors-for-a-success-mia"><a class="markdownIt-Anchor" href="#factors-for-a-success-mia">#</a> Factors for a success MIA</h1>
<h2 id="overfitting-of-target-models"><a class="markdownIt-Anchor" href="#overfitting-of-target-models">#</a> Overfitting of Target Models</h2>
<p>Many studies have pointed out that overfitting of target ML models is a significant factor in the leakage of original datasets. Specifically:Models like DNNs, due to their high parameterization in applications, enhance their ability to handle large datasets but also record a lot of irrelevant information.Training machine learning models often requires many epochs, making them more prone to memorizing the content of the dataset.Machine learning datasets cannot fully represent real-world data.Existing articles indicate that for a classification system overfitting on training data, attackers can achieve an attack success probability higher than 50% based on the correctness of randomly guessed predictions.</p>
<h2 id="features-of-the-model-itself"><a class="markdownIt-Anchor" href="#features-of-the-model-itself">#</a> Features of the Model Itself：</h2>
<p>When the decision boundary of the target model is not sensitive to the training data used, the effectiveness of MIA attacks is low. Current research shows that among DNN models, logistic regression models, Naive Bayes models, k-nearest neighbor models, and decision tree models, decision tree models have the highest attack accuracy, while the simple Naive Bayes algorithm has the lowest.</p>
<h2 id="diversity-of-the-training-dataset"><a class="markdownIt-Anchor" href="#diversity-of-the-training-dataset">#</a> Diversity of the Training Dataset:</h2>
<p>When the training dataset used by the target model is highly diverse, it helps the model generalize better to test data. Consequently, the impact of MIA on the model will be smaller.</p>
<h2 id="attackers-knowledge-of-the-target-model"><a class="markdownIt-Anchor" href="#attackers-knowledge-of-the-target-model">#</a> Attacker’s Knowledge of the Target Model:</h2>
<p>Existing research on MIA generally makes certain assumptions about the attacker: the attacker knows the relevant distribution of the training data and can construct a suitable shadow dataset based on this distribution. High-accuracy shadow models constructed under this assumption are needed for effective attacks.</p>
<h1 id="research-on-defense-against-mia"><a class="markdownIt-Anchor" href="#research-on-defense-against-mia">#</a> Research on Defense against MIA</h1>
<h2 id="confidence-score-masking"><a class="markdownIt-Anchor" href="#confidence-score-masking">#</a> Confidence Score Masking</h2>
<p>This method is mainly used for defending against black-box attacks by returning obfuscated true confidence scores to the classifier. It includes the following three approaches:</p>
<ol>
<li>The target classifier does not provide the full prediction vector but only the top few confidence scores.</li>
<li>The target classifier only provides predicted labels when the attacker provides data input.</li>
<li>Noise is added to the returned vector.</li>
</ol>
<p>These three methods affect the prediction vector but do not result in a loss of prediction accuracy.</p>
<h2 id="regularization"><a class="markdownIt-Anchor" href="#regularization">#</a> Regularization</h2>
<p>Regularization mitigates MIA attack strength by reducing model overfitting.</p>
<p>Existing regularization methods include traditional techniques such as L2-norm regularization, dropout, data augmentation, model stacking, early stopping, and label smoothing. These methods lower overfitting by reducing the impact of different test datasets on samples, thereby also reducing the intensity of MIA attacks.</p>
<p>Additionally, specially designed regularization systems like adversarial regularization and Mixup + MMD (Maximum Mean Discrepancy) can also defend against MIA by introducing new regularization mechanisms to decrease the differences between members and non-members. Compared to masking techniques, regularization can resist both black-box and white-box attacks and can alter output parameters when modifying the output model.</p>
<h2 id="knowledge-distallation"><a class="markdownIt-Anchor" href="#knowledge-distallation">#</a> Knowledge Distallation</h2>
<p>Knowledge distillation refers to the process of training a smaller student model using a larger teacher model to transfer knowledge from the large model to the small one, allowing the smaller model to achieve a similar level of approximation. Based on this, existing research has introduced methods such as DMP, CKD, and PCKD, they are generally called DMP (Distillation For Membership Privacy), whose steps are as followed:</p>
<ol>
<li>Train an unprotected teacher model to record and label data in an unlabeled dataset.</li>
<li>Select data with lower prediction entropy for training, which is used for classification.</li>
<li>Train based on the labeled model.</li>
</ol>
<p>Additionally, There are also some research that proposes Complementary Knowledge Distillation (CKD) and Pseudo Complementary Knowledge Distillation (PCKD) methods. In these methods, the transfer data for knowledge distillation comes from a private training set. CKD and PCKD eliminate the need for public data, which may be difficult to obtain in some applications, making knowledge distillation a more practical defense method for mitigating MIA attacks on machine learning models.</p>
<h2 id="differencial-privacy"><a class="markdownIt-Anchor" href="#differencial-privacy">#</a> Differencial Privacy</h2>
<p>Differential privacy refers to protecting the original data by adding relevant noise to the dataset. When a deep learning model is trained with a model that incorporates differential privacy, if the privacy budget is small enough, the trained model will not retain specific user information. Therefore, different privacy models can limit the success rate of MIA attacks based solely on the model. Current research realms are shown in the next page:</p>
<p>Differential privacy provides theoretical protection for member privacy in training records and can mitigate MIAs in classification and generative models, regardless of whether the attacker is in a black-box or white-box setting. Despite its widespread and effective application, a drawback is its difficulty in providing an acceptable privacy-utility tradeoff in complex learning tasks. Additionally, differential privacy can also mitigate other forms of privacy attacks, such as attribute inference attacks and feature inference attacks, and is related to the robustness of models against adversarial examples.</p>
<p>Currently , the research realms about differencial privacy is:</p>
<p><strong>The relationship between differential privacy and MIA</strong>: There are theoretical results and proofs on this, but practical evaluations have not achieved good utility.</p>
<p><strong>Privacy-Utility Tradeoff</strong>: Existing research shows that current differential privacy performance in this regard is insufficient. Studies indicate that minority groups are more affected by MIAs, and differential privacy reduces model utility for these groups.</p>
<p><strong>Training Methods</strong>: Current methods primarily include DP-SGD, with new methods like DP-Logits also being proposed.</p>
<p><strong>Applications in Generative Models</strong>: Research shows that differential privacy can also defend against MIAs in generative models, with defense effectiveness related to generative quality and privacy budget 𝜖. Studies indicate that differential privacy limits overfitting and mitigates MIA.</p>
<h1 id="possible-future-directions"><a class="markdownIt-Anchor" href="#possible-future-directions">#</a> Possible future directions</h1>
<h2 id="in-membership-inference-attacks"><a class="markdownIt-Anchor" href="#in-membership-inference-attacks">#</a> In Membership Inference Attacks</h2>
<p><strong>Attacks on Regularized Models</strong>: MIA systems often rely on the overfitting of machine learning systems, but this assumption is challenged by advancements in regularization techniques; attacks on overfitted models are still largely unexplored.</p>
<p><strong>Attacks on Self-Supervised Models</strong>: Self-supervised models are becoming widespread in NLP and computer vision, and attacks on these models are still largely unknown.</p>
<p><strong>Attacks on Adversarial Machine Learning</strong>: Adversarial machine learning shares some similarities and differences with membership inference attacks; combining these approaches could be a potential research direction.</p>
<p><strong>Attacks on New Machine Learning Models</strong> (e.g., Contrastive Learning and Meta-Learning): These models differ significantly from traditional ones, and many areas for research remain in attacking them.</p>
<p><strong>Attacks on Federated Learning</strong>: Existing MIAs are mainly applicable to homogeneous federated learning, with limited research on heterogeneous federated learning.</p>
<p><strong>Applications Related to MIA</strong>: Includes source inference attacks in federated learning and deeper privacy protection studies through MIA audits of data contributions to ML models.</p>
<h2 id="in-the-defence-of-membership-inference-attacks"><a class="markdownIt-Anchor" href="#in-the-defence-of-membership-inference-attacks">#</a> In the Defence of Membership Inference Attacks</h2>
<p><strong>Defense Against Unsupervised Learning Models</strong>: Unsupervised learning models struggle with overfitting due to a lack of data labels, and research in this area is limited.</p>
<p><strong>Defense Against Generative Models</strong>: Possible defenses include methods such as knowledge distillation and reinforcemnt learning to avoid leakage of raw data through the outputs of generative models.</p>
<p><strong>Balancing Privacy and Utility</strong>: Existing differential privacy protections often add significant noise to classifier gradients, reducing prediction accuracy. Balancing privacy and utility remains an area for research.</p>
<p><strong>Privacy Defenses in Federated Learning</strong>: With increasing privacy attacks in federated learning, developing defensive technologies is crucial, with differential privacy being a potential future direction.</p>

  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">Edited on</span>
    <time title="Modified: 2024-09-28 21:52:47" itemprop="dateModified" datetime="2024-09-28T21:52:47+08:00">2024-09-28</time>
  </span>
  <span id="2024/08/04/Introduction of MIA/" class="item leancloud_visitors" data-flag-title="Introduction of Membership Interface Attack" title="Views">
      <span class="icon">
        <i class="ic i-eye"></i>
      </span>
      <span class="text">Views</span>
      <span class="leancloud-visitors-count"></span>
      <span class="text">times</span>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> Donate</button>
  <p>Give me a cup of [coffee]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="/images/wechatpay.png" alt="C.K. Tii WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div>
        <img data-src="/images/alipay.png" alt="C.K. Tii Alipay">
        <p>Alipay</p>
      </div>
      
      <div>
        <img data-src="/images/paypal.png" alt="C.K. Tii PayPal">
        <p>PayPal</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>Post author:  </strong>C.K. Tii <i class="ic i-at"><em>@</em></i>张前的小屋
  </li>
  <li class="link">
    <strong>Post link: </strong>
    <a href="https://ckti.github.io/2024/08/04/Introduction%20of%20MIA/" title="Introduction of Membership Interface Attack">https://ckti.github.io/2024/08/04/Introduction of MIA/</a>
  </li>
  <li class="license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2024/08/02/Introduction%20of%20MIA_CN/" itemprop="url" rel="prev" data-background-image="&#x2F;2024&#x2F;08&#x2F;02&#x2F;Introduction%20of%20MIA_CN&#x2F;assets&#x2F;4331Mashiro-Kurata-Power-ni2LcH.png" title="成员推理攻击介绍">
  <span class="type">Previous Post</span>
  <span class="category"><i class="ic i-flag"></i> 成员推断攻击</span>
  <h3>成员推理攻击介绍</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2024/08/11/resume/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;images.weserv.nl&#x2F;?url&#x3D;https:&#x2F;&#x2F;raw.github.com&#x2F;ckt1i&#x2F;blogimage&#x2F;main&#x2F;pic8.jpg" title="resume">
  <span class="type">Next Post</span>
  <span class="category"><i class="ic i-flag"></i> 杂</span>
  <h3>resume</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="Contents">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#prelimaries-defination-and-classification"><span class="toc-number">1.</span> <span class="toc-text"> Prelimaries ,Defination and classification</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#prelimaries-machine-learning"><span class="toc-number">1.1.</span> <span class="toc-text"> Prelimaries-- Machine learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#membership-interface-attackdefination"><span class="toc-number">1.2.</span> <span class="toc-text"> Membership Interface Attack–Defination</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#shadow-models"><span class="toc-number">1.2.1.</span> <span class="toc-text"> Shadow models</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#basic-taxonomy-of-mia"><span class="toc-number">1.3.</span> <span class="toc-text"> Basic Taxonomy of MIA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#based-on-informations"><span class="toc-number">1.3.1.</span> <span class="toc-text"> based on informations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#based-on-prediction-vectors"><span class="toc-number">1.3.2.</span> <span class="toc-text"> based on Prediction vectors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#based-on-the-judgement-methods"><span class="toc-number">1.3.3.</span> <span class="toc-text"> Based on the judgement methods</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#binary-classifier-based-mia"><span class="toc-number">1.3.3.1.</span> <span class="toc-text"> Binary Classifier Based MIA.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#metric-based-membership-inference-attacks"><span class="toc-number">1.3.3.2.</span> <span class="toc-text"> Metric Based Membership Inference Attacks</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#relavant-research"><span class="toc-number">2.</span> <span class="toc-text"> Relavant research</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#research-on-the-classification-models"><span class="toc-number">2.1.</span> <span class="toc-text"> Research on the classification models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#research-on-generative-models"><span class="toc-number">2.2.</span> <span class="toc-text"> Research on Generative Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#research-on-embedding-models"><span class="toc-number">2.3.</span> <span class="toc-text"> Research on Embedding Models：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#research-on-regression-models"><span class="toc-number">2.4.</span> <span class="toc-text"> Research on Regression Models：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#research-in-federated-learning"><span class="toc-number">2.5.</span> <span class="toc-text"> Research in Federated Learning：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#factors-for-a-success-mia"><span class="toc-number">3.</span> <span class="toc-text"> Factors for a success MIA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#overfitting-of-target-models"><span class="toc-number">3.1.</span> <span class="toc-text"> Overfitting of Target Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#features-of-the-model-itself"><span class="toc-number">3.2.</span> <span class="toc-text"> Features of the Model Itself：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#diversity-of-the-training-dataset"><span class="toc-number">3.3.</span> <span class="toc-text"> Diversity of the Training Dataset:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#attackers-knowledge-of-the-target-model"><span class="toc-number">3.4.</span> <span class="toc-text"> Attacker’s Knowledge of the Target Model:</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#research-on-defense-against-mia"><span class="toc-number">4.</span> <span class="toc-text"> Research on Defense against MIA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#confidence-score-masking"><span class="toc-number">4.1.</span> <span class="toc-text"> Confidence Score Masking</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#regularization"><span class="toc-number">4.2.</span> <span class="toc-text"> Regularization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#knowledge-distallation"><span class="toc-number">4.3.</span> <span class="toc-text"> Knowledge Distallation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#differencial-privacy"><span class="toc-number">4.4.</span> <span class="toc-text"> Differencial Privacy</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#possible-future-directions"><span class="toc-number">5.</span> <span class="toc-text"> Possible future directions</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#in-membership-inference-attacks"><span class="toc-number">5.1.</span> <span class="toc-text"> In Membership Inference Attacks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#in-the-defence-of-membership-inference-attacks"><span class="toc-number">5.2.</span> <span class="toc-text"> In the Defence of Membership Inference Attacks</span></a></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="Related">
        <ul>
          <li><a href="/2024/08/02/Introduction%20of%20MIA_CN/" rel="bookmark" title="成员推理攻击介绍">成员推理攻击介绍</a></li><li class="active"><a href="/2024/08/04/Introduction%20of%20MIA/" rel="bookmark" title="Introduction of Membership Interface Attack">Introduction of Membership Interface Attack</a></li><li><a href="/2024/09/26/MIA_1/" rel="bookmark" title="Membership Inference Attacks Against Machine Learning Models">Membership Inference Attacks Against Machine Learning Models</a></li><li><a href="/2024/09/26/MIA_2/" rel="bookmark" title="Membership Inference Attacks Against Recommender Systems">Membership Inference Attacks Against Recommender Systems</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="Overview">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="C.K. Tii"
      data-src="/images/avatar.png">
  <p class="name" itemprop="name">C.K. Tii</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">7</span>
        <span class="name">posts</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">4</span>
        <span class="name">categories</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">1</span>
        <span class="name">tags</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0NLVDFp" title="https:&#x2F;&#x2F;github.com&#x2F;CKT1i"><i class="ic i-github"></i></span>
      <a href="/changqian.zheng@gmail.com" title="changqian.zheng@gmail.com" class="item email"><i class="ic i-envelope"></i></a>
      <span class="exturl item bilibili" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMTg5OTk5NzQ2" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;189999746"><i class="ic i-bilibili"></i></span>
      <a href="/hsource/_data/images/resume.pdf" title="hsource&#x2F;_data&#x2F;images&#x2F;resume.pdf" class="item about"><i class="ic i-address-card"></i></a>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>Home</a>
  </li>

    
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2024/08/02/Introduction%20of%20MIA_CN/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2024/08/11/resume/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>Random Posts</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/DrumTabs/" title="In 鼓谱">鼓谱</a>
</div>

    <span><a href="/2024/08/22/November/" title="November">November</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/ReadingNotes/" title="In 阅读笔记">阅读笔记</a>
<i class="ic i-angle-right"></i>
<a href="/categories/ReadingNotes/MIA/" title="In 成员推断攻击">成员推断攻击</a>
</div>

    <span><a href="/2024/08/04/Introduction%20of%20MIA/" title="Introduction of Membership Interface Attack">Introduction of Membership Interface Attack</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/ReadingNotes/" title="In 阅读笔记">阅读笔记</a>
<i class="ic i-angle-right"></i>
<a href="/categories/ReadingNotes/MIA/" title="In 成员推断攻击">成员推断攻击</a>
</div>

    <span><a href="/2024/08/02/Introduction%20of%20MIA_CN/" title="成员推理攻击介绍">成员推理攻击介绍</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/misc/" title="In 杂">杂</a>
</div>

    <span><a href="/2024/08/01/About%20me/" title="About me">About me</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/misc/" title="In 杂">杂</a>
</div>

    <span><a href="/2024/08/11/resume/" title="resume">resume</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/ReadingNotes/" title="In 阅读笔记">阅读笔记</a>
<i class="ic i-angle-right"></i>
<a href="/categories/ReadingNotes/MIA/" title="In 成员推断攻击">成员推断攻击</a>
</div>

    <span><a href="/2024/09/26/MIA_1/" title="Membership Inference Attacks Against Machine Learning Models">Membership Inference Attacks Against Machine Learning Models</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/ReadingNotes/" title="In 阅读笔记">阅读笔记</a>
<i class="ic i-angle-right"></i>
<a href="/categories/ReadingNotes/MIA/" title="In 成员推断攻击">成员推断攻击</a>
</div>

    <span><a href="/2024/09/26/MIA_2/" title="Membership Inference Attacks Against Recommender Systems">Membership Inference Attacks Against Recommender Systems</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>Recent Comments</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">C.K. Tii @ CKT1i's blog</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="Symbols count total">40k words</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="Reading time total">37 mins.</span>
  </div>
  <div class="powered-by">
    Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2024/08/04/Introduction of MIA/',
    favicon: {
      show: "（●´3｀●）Goooood",
      hide: "(´Д｀)Booooom"
    },
    search : {
      placeholder: "Search for Posts",
      empty: "We didn't find any results for the search: ${query}",
      stats: "${hits} results found in ${time} ms"
    },
    valine: true,fancybox: true,
    copyright: 'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
